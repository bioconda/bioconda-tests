  Package                                      Version  Build                Channel                                   Size
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  Install:
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

  + _libgcc_mutex                                  0.1  conda_forge          conda-forge/linux-64                    Cached
  + _openmp_mutex                                  4.5  1_gnu                conda-forge/linux-64                    Cached
  + appdirs                                      1.4.4  pyh9f0ad1d_0         conda-forge/noarch                       13 KB
  + asn1crypto                                   1.4.0  pyh9f0ad1d_0         conda-forge/noarch                       78 KB
  + avro-python2                                 1.8.1  py27_0               bioconda/linux-64                        74 KB
  + azure                                        4.0.0  py_0                 conda-forge/noarch                        6 KB
  + azure-common                                1.1.24  py_0                 conda-forge/noarch                       12 KB
  + azure-mgmt                                  0.20.1  py27_0               conda-forge/linux-64                      3 KB
  + azure-mgmt-common                           0.20.0  py27_0               conda-forge/linux-64                      8 KB
  + azure-mgmt-compute                          0.20.1  py27_0               conda-forge/linux-64                     79 KB
  + azure-mgmt-network                          0.20.1  py27_0               conda-forge/linux-64                     91 KB
  + azure-mgmt-nspkg                             1.0.0  py27_0               conda-forge/linux-64                      2 KB
  + azure-mgmt-resource                         0.20.1  py27_0               conda-forge/linux-64                     42 KB
  + azure-mgmt-storage                          0.20.0  py27_0               conda-forge/linux-64                     24 KB
  + azure-nspkg                                  3.0.2  py_0                 conda-forge/noarch                        4 KB
  + azure-servicebus                            0.20.1  py27_0               conda-forge/linux-64                     43 KB
  + azure-servicemanagement-legacy              0.20.1  py27_0               conda-forge/linux-64                     97 KB
  + azure-storage                               0.20.3  py27_0               conda-forge/linux-64                     85 KB
  + backports                                      1.0  py27_1               conda-forge/linux-64                      4 KB
  + bd2k-python-lib                       1.14a1.dev37  py27_0               bioconda/linux-64                        79 KB
  + biopython                                     1.76  py27h516909a_0       conda-forge/linux-64                      3 MB
  + boltons                                     21.0.0  pyhd8ed1ab_0         conda-forge/noarch                      211 KB
  + boto                                        2.49.0  py_0                 conda-forge/noarch                      838 KB
  + brotlipy                                     0.7.0  py27h516909a_1000    conda-forge/linux-64                    345 KB
  + ca-certificates                          2021.5.30  ha878542_0           conda-forge/linux-64                    Cached
  + cachecontrol                                0.11.7  py_0                 conda-forge/noarch                       17 KB
  + cachetools                                   3.1.1  py_0                 conda-forge/noarch                       11 KB
  + cactus                                  2019.03.01  py27hdbcaa40_1       /home/vsts/conda/conda-bld/linux-64     372 MB
  + certifi                                 2019.11.28  py27h8c360ce_1       conda-forge/linux-64                    149 KB
  + cffi                                        1.14.0  py27hd463f26_0       conda-forge/linux-64                    217 KB
  + cgcloud-lib                                  1.6.0  py27_2               bioconda/linux-64                        78 KB
  + chardet                                      3.0.4  py27h8c360ce_1006    conda-forge/linux-64                    180 KB
  + cryptography                                   2.5  py27hb7f436b_1       conda-forge/linux-64                    634 KB
  + cwltest                         1.0.20190906212748  py_0                 bioconda/noarch                          17 KB
  + cwltool                         1.0.20180130110340  py27_0               bioconda/linux-64                       255 KB
  + cython                                     0.29.15  py27haf22ab1_1       conda-forge/linux-64                      2 MB
  + decorator                                    4.4.2  py_0                 conda-forge/noarch                       11 KB
  + dill                                         0.3.2  pyh9f0ad1d_0         conda-forge/noarch                       59 KB
  + docker-py                                    4.2.0  py27_0               conda-forge/linux-64                    183 KB
  + docker-pycreds                               0.4.0  py_0                 conda-forge/noarch                       11 KB
  + docutils                                      0.16  py27h8c360ce_1       conda-forge/linux-64                    739 KB
  + enum34                                      1.1.10  py27h8c360ce_1       conda-forge/linux-64                     49 KB
  + future                                      0.18.2  py27h8c360ce_1       conda-forge/linux-64                    722 KB
  + futures                                      3.3.0  py27h8c360ce_1       conda-forge/linux-64                     26 KB
  + galaxy-lib                                  19.5.2  pyh864c0ab_1         bioconda/noarch                         257 KB
  + gcs-oauth2-boto-plugin                         1.9  py27_1               bioconda/linux-64                        40 KB
  + google-api-core                             1.16.0  py27_1               conda-forge/linux-64                     81 KB
  + google-api-python-client                     1.9.1  pyh9f0ad1d_0         conda-forge/noarch                       46 KB
  + google-auth                                 1.16.1  pyh9f0ad1d_0         conda-forge/noarch                       55 KB
  + google-auth-httplib2                         0.0.4  pyh9f0ad1d_0         conda-forge/noarch                       13 KB
  + googleapis-common-protos                    1.51.0  py27_1               conda-forge/linux-64                     66 KB
  + html5lib                                       1.1  pyh9f0ad1d_0         conda-forge/noarch                       89 KB
  + httplib2                                    0.18.1  pyh9f0ad1d_0         conda-forge/noarch                       94 KB
  + idna                                          2.10  pyh9f0ad1d_0         conda-forge/noarch                       52 KB
  + ipaddress                                   1.0.23  py_0                 conda-forge/noarch                       19 KB
  + isodate                                      0.6.0  py_1                 conda-forge/noarch                       25 KB
  + jobtree                                 09.04.2017  py_2                 bioconda/noarch                          51 KB
  + junit-xml                                      1.9  pyh9f0ad1d_0         conda-forge/noarch                       10 KB
  + keepalive                                      0.5  py27_0               conda-forge/linux-64                     14 KB
  + kyototycoon                               20170410  hd344e51_1           bioconda/linux-64                         5 MB
  + libblas                                      3.9.0  11_linux64_openblas  conda-forge/linux-64                    Cached
  + libcblas                                     3.9.0  11_linux64_openblas  conda-forge/linux-64                    Cached
  + libffi                                       3.2.1  he1b5a44_1007        conda-forge/linux-64                     47 KB
  + libgcc-ng                                   11.1.0  hc902ee8_8           conda-forge/linux-64                    Cached
  + libgfortran-ng                              11.1.0  h69a702a_8           conda-forge/linux-64                    Cached
  + libgfortran5                                11.1.0  h6c583b3_8           conda-forge/linux-64                    Cached
  + libgomp                                     11.1.0  hc902ee8_8           conda-forge/linux-64                    Cached
  + liblapack                                    3.9.0  11_linux64_openblas  conda-forge/linux-64                    Cached
  + libopenblas                                 0.3.17  pthreads_h8fe5266_1  conda-forge/linux-64                    Cached
  + libpng                                      1.6.37  h21135ba_2           conda-forge/linux-64                    Cached
  + libprotobuf                                 3.11.4  h8b12597_0           conda-forge/linux-64                      5 MB
  + libstdcxx-ng                                11.1.0  h56837e0_8           conda-forge/linux-64                    Cached
  + libuuid                                     2.32.1  h7f98852_1000        conda-forge/linux-64                    Cached
  + lockfile                                    0.12.2  py27_0               conda-forge/linux-64                     15 KB
  + lzo                                           2.10  h516909a_1000        conda-forge/linux-64                    Cached
  + markupsafe                                   1.1.1  py27hdf8410d_1       conda-forge/linux-64                     26 KB
  + mistune                                      0.7.4  py27_0               conda-forge/linux-64                     24 KB
  + mysql-connector-c                           6.1.11  hab6429c_1002        conda-forge/linux-64                      4 MB
  + ncurses                                        6.2  h58526e2_4           conda-forge/linux-64                    Cached
  + networkx                                      1.11  py27_0               conda-forge/linux-64                      1 MB
  + numpy                                       1.16.5  py27h95a1406_0       conda-forge/linux-64                      4 MB
  + openssl                                     1.0.2u  h516909a_0           conda-forge/linux-64                      3 MB
  + packaging                                     20.9  pyh44b312d_0         conda-forge/noarch                       35 KB
  + pip                                         20.1.1  pyh9f0ad1d_0         conda-forge/noarch                        1 MB
  + protobuf                                    3.11.4  py27he1b5a44_0       conda-forge/linux-64                    696 KB
  + psutil                                       5.7.0  py27hdf8410d_1       conda-forge/linux-64                    318 KB
  + pyasn1                                       0.4.8  py_0                 conda-forge/noarch                       53 KB
  + pyasn1-modules                               0.2.7  py_0                 conda-forge/noarch                       60 KB
  + pycparser                                     2.20  pyh9f0ad1d_2         conda-forge/noarch                      Cached
  + pynacl                                       1.1.2  py27_0               conda-forge/linux-64                    552 KB
  + pyopenssl                                   19.0.0  py27_0               conda-forge/linux-64                     79 KB
  + pyparsing                                    2.4.7  pyh9f0ad1d_0         conda-forge/noarch                      Cached
  + pysocks                                      1.7.1  py27h8c360ce_1       conda-forge/linux-64                     26 KB
  + python                                      2.7.15  h938d71a_1006        conda-forge/linux-64                     12 MB
  + python-dateutil                              2.8.1  py_0                 conda-forge/noarch                      220 KB
  + python_abi                                     2.7  1_cp27mu             conda-forge/linux-64                      4 KB
  + pytz                                        2020.1  pyh9f0ad1d_0         conda-forge/noarch                      227 KB
  + pyyaml                                       5.3.1  py27hdf8410d_0       conda-forge/linux-64                    174 KB
  + rdflib                                       4.2.2  py27_1000            conda-forge/linux-64                    547 KB
  + rdflib-jsonld                                0.4.0  py27_1000            conda-forge/linux-64                     25 KB
  + readline                                       7.0  hf8c457e_1001        conda-forge/linux-64                    391 KB
  + requests                                    2.25.1  pyhd3deb0d_0         conda-forge/noarch                       51 KB
  + retry_decorator                              1.1.1  pyh9f0ad1d_0         conda-forge/noarch                        6 KB
  + rsa                                            4.0  py_0                 conda-forge/noarch                       27 KB
  + ruamel                                         1.0  py27h8c360ce_2       conda-forge/linux-64                      4 KB
  + ruamel.ordereddict                          0.4.14  py27h516909a_0       conda-forge/linux-64                     38 KB
  + ruamel.yaml                                0.14.11  py27_0               conda-forge/linux-64                    555 KB
  + schema-salad                    2.7.20180611133406  py27_0               bioconda/linux-64                       283 KB
  + setuptools                                  44.0.0  py27_0               conda-forge/linux-64                    663 KB
  + shellescape                                  3.4.1  py_0                 conda-forge/noarch                        7 KB
  + simplejson                                  3.17.0  py27hdf8410d_1       conda-forge/linux-64                    102 KB
  + six                                         1.16.0  pyh6c4a22f_0         conda-forge/noarch                      Cached
  + socksipy-branch                               1.01  pyh9f0ad1d_0         conda-forge/noarch                        9 KB
  + sonlib                                       1.1.0  py27_1               bioconda/linux-64                        51 KB
  + sparqlwrapper                                1.8.5  py27h8c360ce_1002    conda-forge/linux-64                     39 KB
  + sqlite                                      3.28.0  h8b20d00_0           conda-forge/linux-64                      2 MB
  + ssl_match_hostname                         3.7.0.1  py_1000              conda-forge/noarch                        8 KB
  + subprocess32                                 3.5.4  py27h516909a_0       conda-forge/linux-64                     46 KB
  + tk                                          8.6.11  h27826a3_1           conda-forge/linux-64                    Cached
  + toil                                        3.14.0  py27_2               bioconda/linux-64                       494 KB
  + typing                                     3.5.3.0  py27_0               conda-forge/linux-64                     36 KB
  + ucsc-bedsort                                   377  h199ee4e_0           bioconda/linux-64                       426 KB
  + ucsc-bedtobigbed                               377  h199ee4e_0           bioconda/linux-64                       447 KB
  + ucsc-bigbedtobed                               377  h199ee4e_0           bioconda/linux-64                       440 KB
  + ucsc-fatotwobit                                377  h199ee4e_1           bioconda/linux-64                       318 KB
  + uritemplate                                  3.0.1  py_0                 conda-forge/noarch                       16 KB
  + urllib3                                     1.26.6  pyhd8ed1ab_0         conda-forge/noarch                      Cached
  + webencodings                                 0.5.1  py_1                 conda-forge/noarch                       12 KB
  + websocket-client                            0.57.0  py27h8c360ce_1       conda-forge/linux-64                     57 KB
  + wheel                                       0.37.0  pyhd8ed1ab_1         conda-forge/noarch                      Cached
  + yaml                                         0.2.5  h516909a_0           conda-forge/linux-64                    Cached
  + zlib                                        1.2.11  h516909a_1010        conda-forge/linux-64                    Cached

  Summary:

  Install: 132 packages

  Total download: 428 MB

─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Updating build index: /home/vsts/conda/conda-bld

TEST START: cactus-2019.03.01-py27hdbcaa40_1.tar.bz2

## Package Plan ##

  environment location: /home/vsts/conda/conda-bld/cactus_1630848292855/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place


The following NEW packages will be INSTALLED:

    _libgcc_mutex:                  0.1-conda_forge            conda-forge
    _openmp_mutex:                  4.5-1_gnu                  conda-forge
    appdirs:                        1.4.4-pyh9f0ad1d_0         conda-forge
    asn1crypto:                     1.4.0-pyh9f0ad1d_0         conda-forge
    avro-python2:                   1.8.1-py27_0               bioconda   
    azure:                          4.0.0-py_0                 conda-forge
    azure-common:                   1.1.24-py_0                conda-forge
    azure-mgmt:                     0.20.1-py27_0              conda-forge
    azure-mgmt-common:              0.20.0-py27_0              conda-forge
    azure-mgmt-compute:             0.20.1-py27_0              conda-forge
    azure-mgmt-network:             0.20.1-py27_0              conda-forge
    azure-mgmt-nspkg:               1.0.0-py27_0               conda-forge
    azure-mgmt-resource:            0.20.1-py27_0              conda-forge
    azure-mgmt-storage:             0.20.0-py27_0              conda-forge
    azure-nspkg:                    3.0.2-py_0                 conda-forge
    azure-servicebus:               0.20.1-py27_0              conda-forge
    azure-servicemanagement-legacy: 0.20.1-py27_0              conda-forge
    azure-storage:                  0.20.3-py27_0              conda-forge
    backports:                      1.0-py27_1                 conda-forge
    bd2k-python-lib:                1.14a1.dev37-py27_0        bioconda   
    biopython:                      1.76-py27h516909a_0        conda-forge
    boltons:                        21.0.0-pyhd8ed1ab_0        conda-forge
    boto:                           2.49.0-py_0                conda-forge
    brotlipy:                       0.7.0-py27h516909a_1000    conda-forge
    ca-certificates:                2021.5.30-ha878542_0       conda-forge
    cachecontrol:                   0.11.7-py_0                conda-forge
    cachetools:                     3.1.1-py_0                 conda-forge
    cactus:                         2019.03.01-py27hdbcaa40_1  local      
    certifi:                        2019.11.28-py27h8c360ce_1  conda-forge
    cffi:                           1.14.0-py27hd463f26_0      conda-forge
    cgcloud-lib:                    1.6.0-py27_2               bioconda   
    chardet:                        3.0.4-py27h8c360ce_1006    conda-forge
    cryptography:                   2.5-py27hb7f436b_1         conda-forge
    cwltest:                        1.0.20190906212748-py_0    bioconda   
    cwltool:                        1.0.20180130110340-py27_0  bioconda   
    cython:                         0.29.15-py27haf22ab1_1     conda-forge
    decorator:                      4.4.2-py_0                 conda-forge
    dill:                           0.3.2-pyh9f0ad1d_0         conda-forge
    docker-py:                      4.2.0-py27_0               conda-forge
    docker-pycreds:                 0.4.0-py_0                 conda-forge
    docutils:                       0.16-py27h8c360ce_1        conda-forge
    enum34:                         1.1.10-py27h8c360ce_1      conda-forge
    future:                         0.18.2-py27h8c360ce_1      conda-forge
    futures:                        3.3.0-py27h8c360ce_1       conda-forge
    galaxy-lib:                     19.5.2-pyh864c0ab_1        bioconda   
    gcs-oauth2-boto-plugin:         1.9-py27_1                 bioconda   
    google-api-core:                1.16.0-py27_1              conda-forge
    google-api-python-client:       1.9.1-pyh9f0ad1d_0         conda-forge
    google-auth:                    1.16.1-pyh9f0ad1d_0        conda-forge
    google-auth-httplib2:           0.0.4-pyh9f0ad1d_0         conda-forge
    googleapis-common-protos:       1.51.0-py27_1              conda-forge
    html5lib:                       1.1-pyh9f0ad1d_0           conda-forge
    httplib2:                       0.18.1-pyh9f0ad1d_0        conda-forge
    idna:                           2.10-pyh9f0ad1d_0          conda-forge
    ipaddress:                      1.0.23-py_0                conda-forge
    isodate:                        0.6.0-py_1                 conda-forge
    jobtree:                        09.04.2017-py_2            bioconda   
    junit-xml:                      1.9-pyh9f0ad1d_0           conda-forge
    keepalive:                      0.5-py27_0                 conda-forge
    kyototycoon:                    20170410-hd344e51_1        bioconda   
    libblas:                        3.9.0-11_linux64_openblas  conda-forge
    libcblas:                       3.9.0-11_linux64_openblas  conda-forge
    libffi:                         3.2.1-he1b5a44_1007        conda-forge
    libgcc-ng:                      11.1.0-hc902ee8_8          conda-forge
    libgfortran-ng:                 11.1.0-h69a702a_8          conda-forge
    libgfortran5:                   11.1.0-h6c583b3_8          conda-forge
    libgomp:                        11.1.0-hc902ee8_8          conda-forge
    liblapack:                      3.9.0-11_linux64_openblas  conda-forge
    libopenblas:                    0.3.17-pthreads_h8fe5266_1 conda-forge
    libpng:                         1.6.37-h21135ba_2          conda-forge
    libprotobuf:                    3.11.4-h8b12597_0          conda-forge
    libstdcxx-ng:                   11.1.0-h56837e0_8          conda-forge
    libuuid:                        2.32.1-h7f98852_1000       conda-forge
    lockfile:                       0.12.2-py27_0              conda-forge
    lzo:                            2.10-h516909a_1000         conda-forge
    markupsafe:                     1.1.1-py27hdf8410d_1       conda-forge
    mistune:                        0.7.4-py27_0               conda-forge
    mysql-connector-c:              6.1.11-hab6429c_1002       conda-forge
    ncurses:                        6.2-h58526e2_4             conda-forge
    networkx:                       1.11-py27_0                conda-forge
    numpy:                          1.16.5-py27h95a1406_0      conda-forge
    openssl:                        1.0.2u-h516909a_0          conda-forge
    packaging:                      20.9-pyh44b312d_0          conda-forge
    pip:                            20.1.1-pyh9f0ad1d_0        conda-forge
    protobuf:                       3.11.4-py27he1b5a44_0      conda-forge
    psutil:                         5.7.0-py27hdf8410d_1       conda-forge
    pyasn1:                         0.4.8-py_0                 conda-forge
    pyasn1-modules:                 0.2.7-py_0                 conda-forge
    pycparser:                      2.20-pyh9f0ad1d_2          conda-forge
    pynacl:                         1.1.2-py27_0               conda-forge
    pyopenssl:                      19.0.0-py27_0              conda-forge
    pyparsing:                      2.4.7-pyh9f0ad1d_0         conda-forge
    pysocks:                        1.7.1-py27h8c360ce_1       conda-forge
    python:                         2.7.15-h938d71a_1006       conda-forge
    python-dateutil:                2.8.1-py_0                 conda-forge
    python_abi:                     2.7-1_cp27mu               conda-forge
    pytz:                           2020.1-pyh9f0ad1d_0        conda-forge
    pyyaml:                         5.3.1-py27hdf8410d_0       conda-forge
    rdflib:                         4.2.2-py27_1000            conda-forge
    rdflib-jsonld:                  0.4.0-py27_1000            conda-forge
    readline:                       7.0-hf8c457e_1001          conda-forge
    requests:                       2.25.1-pyhd3deb0d_0        conda-forge
    retry_decorator:                1.1.1-pyh9f0ad1d_0         conda-forge
    rsa:                            4.0-py_0                   conda-forge
    ruamel:                         1.0-py27h8c360ce_2         conda-forge
    ruamel.ordereddict:             0.4.14-py27h516909a_0      conda-forge
    ruamel.yaml:                    0.14.11-py27_0             conda-forge
    schema-salad:                   2.7.20180611133406-py27_0  bioconda   
    setuptools:                     44.0.0-py27_0              conda-forge
    shellescape:                    3.4.1-py_0                 conda-forge
    simplejson:                     3.17.0-py27hdf8410d_1      conda-forge
    six:                            1.16.0-pyh6c4a22f_0        conda-forge
    socksipy-branch:                1.01-pyh9f0ad1d_0          conda-forge
    sonlib:                         1.1.0-py27_1               bioconda   
    sparqlwrapper:                  1.8.5-py27h8c360ce_1002    conda-forge
    sqlite:                         3.28.0-h8b20d00_0          conda-forge
    ssl_match_hostname:             3.7.0.1-py_1000            conda-forge
    subprocess32:                   3.5.4-py27h516909a_0       conda-forge
    tk:                             8.6.11-h27826a3_1          conda-forge
    toil:                           3.14.0-py27_2              bioconda   
    typing:                         3.5.3.0-py27_0             conda-forge
    ucsc-bedsort:                   377-h199ee4e_0             bioconda   
    ucsc-bedtobigbed:               377-h199ee4e_0             bioconda   
    ucsc-bigbedtobed:               377-h199ee4e_0             bioconda   
    ucsc-fatotwobit:                377-h199ee4e_1             bioconda   
    uritemplate:                    3.0.1-py_0                 conda-forge
    urllib3:                        1.26.6-pyhd8ed1ab_0        conda-forge
    webencodings:                   0.5.1-py_1                 conda-forge
    websocket-client:               0.57.0-py27h8c360ce_1      conda-forge
    wheel:                          0.37.0-pyhd8ed1ab_1        conda-forge
    yaml:                           0.2.5-h516909a_0           conda-forge
    zlib:                           1.2.11-h516909a_1010       conda-forge

Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
export PREFIX=/home/vsts/conda/conda-bld/cactus_1630848292855/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place
export SRC_DIR=/home/vsts/conda/conda-bld/cactus_1630848292855/test_tmp
usage: cactus [-h] [--logOff] [--logCritical] [--logError] [--logWarning]
              [--logInfo] [--logDebug] [--logLevel LOGLEVEL]
              [--logFile LOGFILE] [--rotatingLogging] [--workDir WORKDIR]
              [--stats] [--clean {always,onError,never,onSuccess}]
              [--cleanWorkDir {always,never,onSuccess,onError}]
              [--clusterStats [CLUSTERSTATS]] [--restart]
              [--batchSystem BATCHSYSTEM] [--disableHotDeployment]
              [--parasolCommand PARASOLCOMMAND]
              [--parasolMaxBatches PARASOLMAXBATCHES] [--scale SCALE]
              [--linkImports] [--mesosMaster MESOSMASTERADDRESS]
              [--provisioner {aws}] [--nodeTypes NODETYPES]
              [--nodeOptions NODEOPTIONS] [--minNodes MINNODES]
              [--maxNodes MAXNODES] [--alphaPacking ALPHAPACKING]
              [--betaInertia BETAINERTIA] [--scaleInterval SCALEINTERVAL]
              [--preemptableCompensation PREEMPTABLECOMPENSATION]
              [--nodeStorage NODESTORAGE] [--metrics]
              [--maxServiceJobs MAXSERVICEJOBS]
              [--maxPreemptableServiceJobs MAXPREEMPTABLESERVICEJOBS]
              [--deadlockWait DEADLOCKWAIT]
              [--statePollingWait STATEPOLLINGWAIT] [--defaultMemory INT]
              [--defaultCores FLOAT] [--defaultDisk INT]
              [--defaultPreemptable] [--maxCores INT] [--maxMemory INT]
              [--maxDisk INT] [--retryCount RETRYCOUNT]
              [--maxJobDuration MAXJOBDURATION]
              [--rescueJobsFrequency RESCUEJOBSFREQUENCY] [--disableCaching]
              [--maxLogFileSize MAXLOGFILESIZE] [--writeLogs [WRITELOGS]]
              [--writeLogsGzip [WRITELOGSGZIP]] [--realTimeLogging]
              [--sseKey SSEKEY] [--cseKey CSEKEY]
              [--setEnv NAME=VALUE or NAME]
              [--servicePollingInterval SERVICEPOLLINGINTERVAL]
              [--debugWorker] [--badWorker BADWORKER]
              [--badWorkerFailInterval BADWORKERFAILINTERVAL]
              [--experiment EXPERIMENTFILE] [--buildAvgs] [--buildReference]
              [--buildHal] [--buildFasta]
              [--intermediateResultsUrl INTERMEDIATERESULTSURL]
              [--database DATABASE] [--configFile CONFIGFILE] [--root ROOT]
              [--latest] [--containerImage CONTAINERIMAGE]
              [--binariesMode {docker,local,singularity}]
              jobStore seqFile outputHal

positional arguments:
  seqFile               Seq file
  outputHal             Output HAL file

optional arguments:
  -h, --help            show this help message and exit
  --experiment EXPERIMENTFILE
                        The file containing a link to the experiment
                        parameters
  --buildAvgs           Build trees
  --buildReference      Creates a reference ordering for the flowers
  --buildHal            Build a hal file
  --buildFasta          Build a fasta file of the input sequences (and
                        reference sequence, used with hal output)
  --intermediateResultsUrl INTERMEDIATERESULTSURL
                        URL prefix to save intermediate results like DB dumps
                        to (e.g. prefix-dump-caf, prefix-dump-avg, etc.)
  --database DATABASE   Database type: tokyo_cabinet or kyoto_tycoon [default:
                        kyoto_tycoon]
  --configFile CONFIGFILE
                        Specify cactus configuration file
  --root ROOT           Name of ancestral node (which must appear in NEWICK
                        tree in <seqfile>) to use as a root for the alignment.
                        Any genomes not below this node in the tree may be
                        used as outgroups but will never appear in the output.
                        If no root is specifed then the root of the tree is
                        used.
  --latest              Use the latest version of the docker container rather
                        than pulling one matching this version of cactus
  --containerImage CONTAINERIMAGE
                        Use the the specified pre-built containter image
                        rather than pulling one from quay.io
  --binariesMode {docker,local,singularity}
                        The way to run the Cactus binaries

Logging Options:
  Options that control logging

  --logOff              Same as --logCritical
  --logCritical         Turn on logging at level CRITICAL and above. (default
                        is INFO)
  --logError            Turn on logging at level ERROR and above. (default is
                        INFO)
  --logWarning          Turn on logging at level WARNING and above. (default
                        is INFO)
  --logInfo             Turn on logging at level INFO and above. (default is
                        INFO)
  --logDebug            Turn on logging at level DEBUG and above. (default is
                        INFO)
  --logLevel LOGLEVEL   Log at given level (may be either OFF (or CRITICAL),
                        ERROR, WARN (or WARNING), INFO or DEBUG). (default is
                        INFO)
  --logFile LOGFILE     File to log in
  --rotatingLogging     Turn on rotating logging, which prevents log files
                        getting too big.

toil core options:
  Options to specify the location of the Toil workflow and turn on stats
  collation about the performance of jobs.

  jobStore              The location of the job store for the workflow. A job
                        store holds persistent information about the jobs and
                        files in a workflow. If the workflow is run with a
                        distributed batch system, the job store must be
                        accessible by all worker nodes. Depending on the
                        desired job store implementation, the location should
                        be formatted according to one of the following
                        schemes: file:<path> where <path> points to a
                        directory on the file systen aws:<region>:<prefix>
                        where <region> is the name of an AWS region like us-
                        west-2 and <prefix> will be prepended to the names of
                        any top-level AWS resources in use by job store, e.g.
                        S3 buckets. azure:<account>:<prefix>
                        google:<project_id>:<prefix> TODO: explain For
                        backwards compatibility, you may also specify ./foo
                        (equivalent to file:./foo or just file:foo) or /bar
                        (equivalent to file:/bar).
  --workDir WORKDIR     Absolute path to directory where temporary files
                        generated during the Toil run should be placed. Temp
                        files and folders will be placed in a directory
                        toil-<workflowID> within workDir (The workflowID is
                        generated by Toil and will be reported in the workflow
                        logs. Default is determined by the variables (TMPDIR,
                        TEMP, TMP) via mkdtemp. This directory needs to exist
                        on all machines running jobs.
  --stats               Records statistics about the toil workflow to be used
                        by 'toil stats'.
  --clean {always,onError,never,onSuccess}
                        Determines the deletion of the jobStore upon
                        completion of the program. Choices: 'always',
                        'onError','never', 'onSuccess'. The --stats option
                        requires information from the jobStore upon completion
                        so the jobStore will never be deleted withthat flag.
                        If you wish to be able to restart the run, choose
                        'never' or 'onSuccess'. Default is 'never' if stats is
                        enabled, and 'onSuccess' otherwise
  --cleanWorkDir {always,never,onSuccess,onError}
                        Determines deletion of temporary worker directory upon
                        completion of a job. Choices: 'always', 'never',
                        'onSuccess'. Default = always. WARNING: This option
                        should be changed for debugging only. Running a full
                        pipeline with this option could fill your disk with
                        intermediate data.
  --clusterStats [CLUSTERSTATS]
                        If enabled, writes out JSON resource usage statistics
                        to a file. The default location for this file is the
                        current working directory, but an absolute path can
                        also be passed to specify where this file should be
                        written. This options only applies when using scalable
                        batch systems.

toil options for restarting an existing workflow:
  Allows the restart of an existing workflow

  --restart             If --restart is specified then will attempt to restart
                        existing workflow at the location pointed to by the
                        --jobStore option. Will raise an exception if the
                        workflow does not exist

toil options for specifying the batch system:
  Allows the specification of the batch system, and arguments to the batch
  system/big batch system (see below).

  --batchSystem BATCHSYSTEM
                        The type of batch system to run the job(s) with,
                        currently can be one of LSF, Mesos, Slurm, Torque,
                        HTCondor, singleMachine, parasol, gridEngine'.
                        default=singleMachine
  --disableHotDeployment
                        Should hot-deployment of the user script be
                        deactivated? If True, the user script/package should
                        be present at the same location on all workers.
                        default=false
  --parasolCommand PARASOLCOMMAND
                        The name or path of the parasol program. Will be
                        looked up on PATH unless it starts with a
                        slashdefault=parasol
  --parasolMaxBatches PARASOLMAXBATCHES
                        Maximum number of job batches the Parasol batch is
                        allowed to create. One batch is created for jobs with
                        a a unique set of resource requirements. default=1000
  --scale SCALE         A scaling factor to change the value of all submitted
                        tasks's submitted cores. Used in singleMachine batch
                        system. default=1
  --linkImports         When using Toil's importFile function for staging,
                        input files are copied to the job store. Specifying
                        this option saves space by sym-linking imported files.
                        As long as caching is enabled Toil will protect the
                        file automatically by changing the permissions to
                        read-only.
  --mesosMaster MESOSMASTERADDRESS
                        The host and port of the Mesos master separated by
                        colon. (default: 10.1.0.233:5050)

toil options for autoscaling the cluster of worker nodes:
  Allows the specification of the minimum and maximum number of nodes in an
  autoscaled cluster, as well as parameters to control the level of
  provisioning.

  --provisioner {aws}   The provisioner for cluster auto-scaling. The
                        currently supported choices are'cgcloud' or 'aws'. The
                        default is None.
  --nodeTypes NODETYPES
                        List of node types separated by commas. The syntax for
                        each node type depends on the provisioner used. For
                        the cgcloud and AWS provisioners this is the name of
                        an EC2 instance type, optionally followed by a colon
                        and the price in dollars to bid for a spot instance of
                        that type, for example 'c3.8xlarge:0.42'.If no spot
                        bid is specified, nodes of this type will be non-
                        preemptable.It is acceptable to specify an instance as
                        both preemptable and non-preemptable, including it
                        twice in the list. In that case,preemptable nodes of
                        that type will be preferred when creating new nodes
                        once the maximum number of preemptable-nodes has
                        beenreached.
  --nodeOptions NODEOPTIONS
                        Options for provisioning the nodes. The syntax depends
                        on the provisioner used. Neither the CGCloud nor the
                        AWS provisioner support any node options.
  --minNodes MINNODES   Mininum number of nodes of each type in the cluster,
                        if using auto-scaling. This should be provided as a
                        comma-separated list of the same length as the list of
                        node types. default=0
  --maxNodes MAXNODES   Maximum number of nodes of each type in the cluster,
                        if using autoscaling, provided as a comma-separated
                        list. The first value is used as a default if the list
                        length is less than the number of nodeTypes.
                        default=10
  --alphaPacking ALPHAPACKING
                        The total number of nodes estimated to be required to
                        compute the issued jobs is multiplied by the alpha
                        packing parameter to produce the actual number of
                        nodes requested. Values of this coefficient greater
                        than one will tend to over provision and values less
                        than one will under provision. default=0.8
  --betaInertia BETAINERTIA
                        A smoothing parameter to prevent unnecessary
                        oscillations in the number of provisioned nodes. If
                        the number of nodes is within the beta inertia of the
                        currently provisioned number of nodes then no change
                        is made to the number of requested nodes. default=1.2
  --scaleInterval SCALEINTERVAL
                        The interval (seconds) between assessing if the scale
                        of the cluster needs to change. default=30
  --preemptableCompensation PREEMPTABLECOMPENSATION
                        The preference of the autoscaler to replace
                        preemptable nodes with non-preemptable nodes, when
                        preemptable nodes cannot be started for some reason.
                        Defaults to 0.0. This value must be between 0.0 and
                        1.0, inclusive. A value of 0.0 disables such
                        compensation, a value of 0.5 compensates two missing
                        preemptable nodes with a non-preemptable one. A value
                        of 1.0 replaces every missing pre-emptable node with a
                        non-preemptable one.
  --nodeStorage NODESTORAGE
                        Specify the size of the root volume of worker nodes
                        when they are launched in gigabytes. You may want to
                        set this if your jobs require a lot of disk space. The
                        default value is 50.
  --metrics             Enable the prometheus/grafana dashboard for monitoring
                        CPU/RAM usage, queue size, and issued jobs.

toil options for limiting the number of service jobs and detecting service deadlocks:
  Allows the specification of the maximum number of service jobs in a
  cluster. By keeping this limited we can avoid all the nodes being occupied
  with services, so causing a deadlock

  --maxServiceJobs MAXSERVICEJOBS
                        The maximum number of service jobs that can be run
                        concurrently, excluding service jobs running on
                        preemptable nodes. default=9223372036854775807
  --maxPreemptableServiceJobs MAXPREEMPTABLESERVICEJOBS
                        The maximum number of service jobs that can run
                        concurrently on preemptable nodes.
                        default=9223372036854775807
  --deadlockWait DEADLOCKWAIT
                        The minimum number of seconds to observe the cluster
                        stuck running only the same service jobs before
                        throwing a deadlock exception. default=60
  --statePollingWait STATEPOLLINGWAIT
                        Time, in seconds, to wait before doing a scheduler
                        query for job state. Return cached results if within
                        the waiting period.

toil options for cores/memory requirements:
  The options to specify default cores/memory requirements (if not specified
  by the jobs themselves), and to limit the total amount of memory/cores
  requested from the batch system.

  --defaultMemory INT   The default amount of memory to request for a job.
                        Only applicable to jobs that do not specify an
                        explicit value for this requirement. Standard suffixes
                        like K, Ki, M, Mi, G or Gi are supported. Default is
                        2.0 Gi
  --defaultCores FLOAT  The default number of CPU cores to dedicate a job.
                        Only applicable to jobs that do not specify an
                        explicit value for this requirement. Fractions of a
                        core (for example 0.1) are supported on some batch
                        systems, namely Mesos and singleMachine. Default is
                        1.0
  --defaultDisk INT     The default amount of disk space to dedicate a job.
                        Only applicable to jobs that do not specify an
                        explicit value for this requirement. Standard suffixes
                        like K, Ki, M, Mi, G or Gi are supported. Default is
                        2.0 Gi
  --defaultPreemptable
  --maxCores INT        The maximum number of CPU cores to request from the
                        batch system at any one time. Standard suffixes like
                        K, Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei
  --maxMemory INT       The maximum amount of memory to request from the batch
                        system at any one time. Standard suffixes like K, Ki,
                        M, Mi, G or Gi are supported. Default is 8.0 Ei
  --maxDisk INT         The maximum amount of disk space to request from the
                        batch system at any one time. Standard suffixes like
                        K, Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei

toil options for rescuing/killing/restarting jobs:
  The options for jobs that either run too long/fail or get lost (some batch
  systems have issues!)

  --retryCount RETRYCOUNT
                        Number of times to retry a failing job before giving
                        up and labeling job failed. default=1
  --maxJobDuration MAXJOBDURATION
                        Maximum runtime of a job (in seconds) before we kill
                        it (this is a lower bound, and the actual time before
                        killing the job may be longer).
                        default=9223372036854775807
  --rescueJobsFrequency RESCUEJOBSFREQUENCY
                        Period of time to wait (in seconds) between checking
                        for missing/overlong jobs, that is jobs which get lost
                        by the batch system. Expert parameter. default=3600

toil miscellaneous options:
  Miscellaneous options

  --disableCaching      Disables caching in the file store. This flag must be
                        set to use a batch system that does not support
                        caching such as Grid Engine, Parasol, LSF, or Slurm
  --maxLogFileSize MAXLOGFILESIZE
                        The maximum size of a job log file to keep (in bytes),
                        log files larger than this will be truncated to the
                        last X bytes. Setting this option to zero will prevent
                        any truncation. Setting this option to a negative
                        value will truncate from the beginning.Default=62.5 K
  --writeLogs [WRITELOGS]
                        Write worker logs received by the leader into their
                        own files at the specified path. The current working
                        directory will be used if a path is not specified
                        explicitly. Note: By default only the logs of failed
                        jobs are returned to leader. Set log level to 'debug'
                        to get logs back from successful jobs, and adjust
                        'maxLogFileSize' to control the truncation limit for
                        worker logs.
  --writeLogsGzip [WRITELOGSGZIP]
                        Identical to --writeLogs except the logs files are
                        gzipped on the leader.
  --realTimeLogging     Enable real-time logging from workers to masters
  --sseKey SSEKEY       Path to file containing 32 character key to be used
                        for server-side encryption on awsJobStore or
                        googleJobStore. SSE will not be used if this flag is
                        not passed.
  --cseKey CSEKEY       Path to file containing 256-bit key to be used for
                        client-side encryption on azureJobStore. By default,
                        no encryption is used.
  --setEnv NAME=VALUE or NAME, -e NAME=VALUE or NAME
                        Set an environment variable early on in the worker. If
                        VALUE is omitted, it will be looked up in the current
                        environment. Independently of this option, the worker
                        will try to emulate the leader's environment before
                        running a job. Using this option, a variable can be
                        injected into the worker process itself before it is
                        started.
  --servicePollingInterval SERVICEPOLLINGINTERVAL
                        Interval of time service jobs wait between polling for
                        the existence of the keep-alive flag (defailt=60)

toil debug options:
  Debug options

  --debugWorker         Experimental no forking mode for local debugging.
                        Specifically, workers are not forked and stderr/stdout
                        are not redirected to the log.
  --badWorker BADWORKER
                        For testing purposes randomly kill 'badWorker'
                        proportion of jobs using SIGKILL, default=0.0
  --badWorkerFailInterval BADWORKERFAILINTERVAL
                        When killing the job pick uniformly within the
                        interval from 0.0 to 'badWorkerFailInterval' seconds
                        after the worker starts, default=0.01
Usage: hal2assemblyHub.py <halFile> <outputDirectory> [options]

Options:
  -h, --help            show this help message and exit
  --cpHalFileToOut      If specified, copy the input halfile to the output
                        directory (instead of just make a softlink).
                        Default=False
  --ucscNames           Assume that sequence headers use the UCSC naming
                        convention, (i.e. "genome.chr"), and  attempt to
                        rename the sequences so that their names will end up
                        as "chr"

  HUB INFORMATION:
    --hub=HUBLABEL      a single-word name of the directory containing the
                        track hub files. Not displayed to hub users.
                        Default=myHub
    --shortLabel=SHORTLABEL
                        the short name for the track hub. Suggested maximum
                        length is 17 characters. Displayed as the hub name on
                        the Track Hubs page and the track group name on the
                        browser tracks page. Default=my hub
    --longLabel=LONGLABEL
                        a longer descriptive label for the track hub.
                        Suggested maximum length is 80 characters. Displayed
                        in the description field on the Track Hubs page.
                        Default=my hub
    --email=EMAIL       the contact to whom questions regarding the track hub
                        should be directed. Default=NoEmail
    --genomes=GENOMES   File specified list of genomes to make browser for. If
                        specified, only create browsers for these genomes in
                        the order provided by the list. Otherwise create
                        browsers for all genomes in the input hal file
    --rename=RENAME     File that maps halfile genomeNames to names displayed
                        on the browser. Format:
                        <halGenomeName>\t<genomeNameToDisplayOnBrowser>.
                        Default=none
    --tree=TREEFILE     Newick binary tree. The order of the tracks and the
                        default track layout will be based on this tree if
                        option "genomes" is not specified. If not specified,
                        try to extract the newick tree from the input halfile.
    --url=URL           Public url of the hub location
    --twobitdir=TWOBITDIR
                        Optional. Directory containing the 2bit files of each
                        genomes. Default: extract from the input hal file.

  LEVEL OF DETAILS:
    Level-of-detail (LOD) options.

    --lod               If specified, create "level of detail" (lod) hal files
                        and will put the lod.txt at the bigUrl instead of the
                        original hal file. Default=False
    --lodTxtFile=LODTXTFILE
                        "hal Level of detail" lod text file. If specified,
                        will put this at the bigUrl instead of the hal file.
                        Default=none
    --lodDir=LODDIR     "hal Level of detail" lod dir. If specified, will put
                        this at the bigUrl instead of the hal file.
                        Default=none
    --lodMaxBlock=LODMAXBLOCK
                        Maximum number of blocks to display in a hal level of
                        detail (see halLodInterpolate.py --help for the
                        default value).
    --lodScale=LODSCALE
                        Scaling factor between two successive levels of detail
                        (see halLodInterpolate.py --help for the default
                        value).
    --lodMaxDNA=LODMAXDNA
                        Maximum query length such that its hal level of detail
                        will contain nucleotide information. Default=none (see
                        halLodInterpolate.py --help for the default value).
    --lodInMemory       Load entire hal file into memory when generating
                        levels of detail instead of using hdf5 cache. Could
                        result in drastic speedup. Default=False.
    --lodMinSeqFrac=LODMINSEQFRAC
                        Minumum sequence length to sample as fraction of step
                        size for level of detail generation: ie sequences with
                        length <= floor(minSeqFrac * step) are ignored (see
                        halLodExtract --help for default value).
    --lodMinCovFrac=LODMINCOVFRAC
                        Minimum fraction of a genome that must be covered by
                        sequences that exceed --minSeqFrac * step.  LODs that
                        would violate this threshold will not be generated (or
                        displayed in  the browser).  This is seen a better
                        than the alternative, which is to produce unreasonably
                        sparse LODs because half the sequences were not
                        sampled (see halLodInterpolate.py --help for default
                        value).
    --lodChunk=LODCHUNK
                        HDF5 chunk size for generated levels of detail (see
                        halLodExtract --help for default value).

  BED-FORMATTED ANNOTATIONS:
    All annotations in bed or bigbed formats.

    --bedDirs=BEDDIRS   comma separated list of directories containing bed
                        files of the input genomes. Each directory represents
                        a type of annotation. The annotations of each genome
                        will then be liftovered to all other genomes in the
                        MSA. Example: "genes,genomicIsland,tRNA". Format of
                        each directory: bedDir/ then genome1/ then chr1.bed,
                        chr2.bed... Default=none
    --finalBigBedDirs=BBDIRS
                        comma separated list of directories containing final
                        big bed files to be displayed. No liftover will be
                        done for these files. Each directory represents a type
                        of annotation. Example: "genes,genomicIsland,tRNA".
                        Format of each directory: bbDir/ then queryGenome/
                        then targetGenome1.bb, targetGenome2.bb ... (so
                        annotation of queryGenome has been mapped to
                        targetGenomes and will be display on the targetGenome
                        browsers). Default=none
    --bedDirs2=BEDDIRS2
                        Similar to --bedDirs, except these tracks will be kept
                        separately and out of the composite track.
                        Default=none
    --finalBigBedDirs2=BBDIRS2
                        Similar to --finalBigBedDirs, except these tracks will
                        be kept separately and out of the composite track.
                        Default=none
    --noBedLiftover     If specified, will not lift over the bed annotations.
                        Default=False
    --tabBed            If specified, treat tab as the delimiter of all the
                        bed files. Default: any white space.

  WIGGLE-FORMATTED ANNOTATIONS:
    All annotations in wiggle or bigWig formats.

    --wigDirs=WIGDIRS   comma separated list of directories containing wig
                        files of the input genomes. Each directory represents
                        a type of annotation. The annotations of each genome
                        will then be liftovered to all other genomes in the
                        MSA. Example: "genes,genomicIsland,tRNA". Format of
                        each directory: wigDir/ then genome1/ then chr1.wig,
                        chr2.wig... Default=none
    --finalBigwigDirs=BWDIRS
                        comma separated list of directories containing final
                        big wig files to be displayed. No liftover will be
                        done for these files. Each directory represents a type
                        of annotation. Example: "readCoverage,". Format of
                        each directory: bwDir/ then queryGenome/ then
                        targetGenome1.bw, targetGenome2.bw ... (so annotation
                        of queryGenome has been mapped to targetGenomes and
                        will be display on the targetGenome browsers).
                        Default=none
    --nowigLiftover     If specified, will not lift over the wig annotations.
                        Default=False

  REPEATMASKER:
    --rmskDir=RMSKDIR   Directory containing repeatMasker's output files for
                        each genome. Format: rmskDir/ then genome1/ then
                        genome.rmsk.SINE.bb, genome.rmsk.LINE.bb, ...
                        Default=none

  GC PERCENT:
    --gcContent         If specified, make GC-content tracks. Default=False

  ALIGNABILITY:
    --alignability      If specified, make Alignability (aka Alignment Depth)
                        tracks. Default=False

  CONSERVATION TRACKS:
    Necessary information for computing conservation tracks

    --conservation=CONSERVATION
                        Bed file providing regions to calculate the
                        conservation tracks.
    --conservationDir=CONSERVATIONDIR
                        Optional. Directory contains conservation bigwigs if
                        available. These bigwigs will be used. If this is not
                        specified, the program will compute the conservation
                        tracks.
    --conservationGenomeName=CONSERVATIONGENOMENAME
                        Name of the genome of the bed file provided in the "--
                        conversation" option
    --conservationTree=CONSERVATIONTREE
                        Optional. Newick tree for the conservation track
    --conservationNumProc=CONSERVATIONNUMPROC
                        Optional. Number of processors to run conservation

  CLADE EXCLUSIVE REGIONS:
    Requirements of regions that are exclusive to subgroup of genomes.

    --cladeExclusiveRegions
                        If specified, will generate tracks of regions that are
                        exclusive to each branch (including leaf "branches",
                        which will be genome-exclusive regions) on the tree.
                        Default=False
    --maxOutgroupGenomes=MAXOUT
                        Maximum number of outgroup genomes that a region is
                        allowed to be in. Default=0
    --minIngroupGenomes=MININ
                        Minimum number of ingroup genomes that a region must
                        appear in. Default=all ingroup genomes (branch node
                        and all its children).

  SNAKE TRACKS:
    Snake track options

    --selfAlignmentSnakes
                        Produce a self-alignment snake track for every genome

  Logging options:
    Options that control logging

    --logOff            Turn off logging. (default is CRITICAL)
    --logInfo           Turn on logging at INFO level. (default is CRITICAL)
    --logDebug          Turn on logging at DEBUG level. (default is CRITICAL)
    --logLevel=LOGLEVEL
                        Log at level (may be either OFF/INFO/DEBUG/CRITICAL).
                        (default is CRITICAL)
    --logFile=LOGFILE   File to log in
    --rotatingLogging   Turn on rotating logging, which prevents log files
                        getting too big.

  jobTree core options:
    Options to specify the location of the jobTree and turn on stats
    collation about the performance of jobs.

    --jobTree=JOBTREE   Directory in which to place job management files and
                        the global accessed temporary file directories(this
                        needs to be globally accessible by all machines
                        running jobs). If you pass an existing directory it
                        will check if it's a valid existing job tree, then try
                        and restart the jobs in it. The default=./jobTree
    --stats             Records statistics about the job-tree to be used by
                        jobTreeStats. default=False

  jobTree options for specifying the batch system:
    Allows the specification of the batch system, and arguments to the
    batch system/big batch system (see below).

    --batchSystem=BATCHSYSTEM
                        The type of batch system to run the job(s) with,
                        currently can be 'singleMachine'/'parasol'/'acidTest'/
                        'gridEngine'/'lsf'. default=singleMachine
    --maxThreads=MAXTHREADS
                        The maximum number of threads (technically processes
                        at this point) to use when running in single machine
                        mode. Increasing this will allow more jobs to run
                        concurrently when running on a single machine.
                        default=4
    --parasolCommand=PARASOLCOMMAND
                        The command to run the parasol program default=parasol

  jobTree options for cpu/memory requirements:
    The options to specify default cpu/memory requirements (if not
    specified by the jobs themselves), and to limit the total amount of
    memory/cpu requested from the batch system.

    --defaultMemory=DEFAULTMEMORY
                        The default amount of memory to request for a job (in
                        bytes), by default is 2^31 = 2 gigabytes,
                        default=2147483648
    --defaultCpu=DEFAULTCPU
                        The default the number of cpus to dedicate a job.
                        default=1
    --maxCpus=MAXCPUS   The maximum number of cpus to request from the batch
                        system at any one time. default=9223372036854775807
    --maxMemory=MAXMEMORY
                        The maximum amount of memory to request from the batch
                        system at any one time. default=9223372036854775807

  jobTree options for rescuing/killing/restarting jobs:
    The options for jobs that either run too long/fail or get lost (some
    batch systems have issues!)

    --retryCount=RETRYCOUNT
                        Number of times to retry a failing job before giving
                        up and labeling job failed. default=0
    --maxJobDuration=MAXJOBDURATION
                        Maximum runtime of a job (in seconds) before we kill
                        it (this is a lower bound, and the actual time before
                        killing the job may be longer).
                        default=9223372036854775807
    --rescueJobsFrequency=RESCUEJOBSFREQUENCY
                        Period of time to wait (in seconds) between checking
                        for missing/overlong jobs, that is jobs which get lost
                        by the batch system. Expert parameter. (default is set
                        by the batch system)

  jobTree big batch system options:
    jobTree can employ a secondary batch system for running large
    memory/cpu jobs using the following arguments:

    --bigBatchSystem=BIGBATCHSYSTEM
                        The batch system to run for jobs with larger
                        memory/cpus requests, currently can be
                        'singleMachine'/'parasol'/'acidTest'/'gridEngine'.
                        default=none
    --bigMemoryThreshold=BIGMEMORYTHRESHOLD
                        The memory threshold above which to submit to the big
                        queue. default=9223372036854775807
    --bigCpuThreshold=BIGCPUTHRESHOLD
                        The cpu threshold above which to submit to the big
                        queue. default=9223372036854775807
    --bigMaxCpus=BIGMAXCPUS
                        The maximum number of big batch system cpus to allow
                        at one time on the big queue.
                        default=9223372036854775807
    --bigMaxMemory=BIGMAXMEMORY
                        The maximum amount of memory to request from the big
                        batch system at any one time.
                        default=9223372036854775807

  jobTree miscellaneous options:
    Miscellaneous options

    --jobTime=JOBTIME   The approximate time (in seconds) that you'd like a
                        list of child jobs to be run serially before being
                        parallelized. This parameter allows one to avoid over
                        parallelizing tiny jobs, and therefore paying
                        significant scheduling overhead, by running tiny jobs
                        in series on a single node/core of the cluster.
                        default=30
    --maxLogFileSize=MAXLOGFILESIZE
                        The maximum size of a job log file to keep (in bytes),
                        log files larger than this will be truncated to the
                        last X bytes. Default is 50 kilobytes, default=50120
    --command=COMMAND   The command to run (which will generate subsequent
                        jobs). This is deprecated

Resource usage statistics from testing cactus:
   Process count: 1
   CPU time: Sys=0:00:00.0, User=-
   Memory: 3.4M
   Disk usage: 16B
   Time elapsed: 0:00:02.1


TEST END: cactus-2019.03.01-py27hdbcaa40_1.tar.bz2
--dirty flag and --keep-old-work not specified. Removing build/test folder after successful build/test.

